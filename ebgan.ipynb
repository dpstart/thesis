{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)\n",
    "\n",
    "def sample_z(n,m):\n",
    "    return np.random.uniform(-1.,1., size=[n,m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = tf.placeholder(tf.float32, shape=[None, 100])\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    with tf.variable_scope(\"generator\",reuse=tf.AUTO_REUSE):\n",
    "        x =  tf.layers.dense(z, 128, activation=tf.nn.relu)\n",
    "        x =  tf.layers.dense(x,784)\n",
    "        x = tf.nn.sigmoid(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x):\n",
    "    with tf.variable_scope(\"discriminator\",reuse=tf.AUTO_REUSE):\n",
    "        enc = tf.layers.dense(x, 128, activation=tf.nn.relu)\n",
    "        dec = tf.layers.dense(enc, 784)\n",
    "        mse = tf.reduce_mean(tf.reduce_sum((x - dec)**2, 1))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_sample = generator(Z)\n",
    "D_real = discriminator(X)\n",
    "D_fake = discriminator(G_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m=5\n",
    "D_loss = D_real + tf.maximum(0., m-D_fake)\n",
    "G_loss = D_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list = [v for v in tf.trainable_variables() if v.name.startswith('disc')])\n",
    "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list = [v for v in tf.trainable_variables() if v.name.startswith('gen')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "z_size = 100\n",
    "mb_size = 16\n",
    "\n",
    "mnist = input_data.read_data_sets('../data/MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "D loss: 105.2\n",
      "G_loss: 208.5\n",
      "\n",
      "Iter: 100\n",
      "D loss: 30.29\n",
      "G_loss: 6.579\n",
      "\n",
      "Iter: 200\n",
      "D loss: 19.77\n",
      "G_loss: 7.052\n",
      "\n",
      "Iter: 300\n",
      "D loss: 14.99\n",
      "G_loss: 5.152\n",
      "\n",
      "Iter: 400\n",
      "D loss: 15.0\n",
      "G_loss: 5.455\n",
      "\n",
      "Iter: 500\n",
      "D loss: 13.6\n",
      "G_loss: 5.254\n",
      "\n",
      "Iter: 600\n",
      "D loss: 9.509\n",
      "G_loss: 5.618\n",
      "\n",
      "Iter: 700\n",
      "D loss: 11.62\n",
      "G_loss: 5.128\n",
      "\n",
      "Iter: 800\n",
      "D loss: 9.901\n",
      "G_loss: 5.079\n",
      "\n",
      "Iter: 900\n",
      "D loss: 10.42\n",
      "G_loss: 5.429\n",
      "\n",
      "Iter: 1000\n",
      "D loss: 9.347\n",
      "G_loss: 5.057\n",
      "\n",
      "Iter: 1100\n",
      "D loss: 9.592\n",
      "G_loss: 5.535\n",
      "\n",
      "Iter: 1200\n",
      "D loss: 8.553\n",
      "G_loss: 5.776\n",
      "\n",
      "Iter: 1300\n",
      "D loss: 9.086\n",
      "G_loss: 5.757\n",
      "\n",
      "Iter: 1400\n",
      "D loss: 9.623\n",
      "G_loss: 6.629\n",
      "\n",
      "Iter: 1500\n",
      "D loss: 8.636\n",
      "G_loss: 6.17\n",
      "\n",
      "Iter: 1600\n",
      "D loss: 8.166\n",
      "G_loss: 5.188\n",
      "\n",
      "Iter: 1700\n",
      "D loss: 7.875\n",
      "G_loss: 5.159\n",
      "\n",
      "Iter: 1800\n",
      "D loss: 8.469\n",
      "G_loss: 6.269\n",
      "\n",
      "Iter: 1900\n",
      "D loss: 7.626\n",
      "G_loss: 5.429\n",
      "\n",
      "Iter: 2000\n",
      "D loss: 8.065\n",
      "G_loss: 5.691\n",
      "\n",
      "Iter: 2100\n",
      "D loss: 7.315\n",
      "G_loss: 5.83\n",
      "\n",
      "Iter: 2200\n",
      "D loss: 7.367\n",
      "G_loss: 6.426\n",
      "\n",
      "Iter: 2300\n",
      "D loss: 7.506\n",
      "G_loss: 6.161\n",
      "\n",
      "Iter: 2400\n",
      "D loss: 7.148\n",
      "G_loss: 5.166\n",
      "\n",
      "Iter: 2500\n",
      "D loss: 7.967\n",
      "G_loss: 5.166\n",
      "\n",
      "Iter: 2600\n",
      "D loss: 7.608\n",
      "G_loss: 5.71\n",
      "\n",
      "Iter: 2700\n",
      "D loss: 8.729\n",
      "G_loss: 5.429\n",
      "\n",
      "Iter: 2800\n",
      "D loss: 6.714\n",
      "G_loss: 6.253\n",
      "\n",
      "Iter: 2900\n",
      "D loss: 6.315\n",
      "G_loss: 5.996\n",
      "\n",
      "Iter: 3000\n",
      "D loss: 6.996\n",
      "G_loss: 7.048\n",
      "\n",
      "Iter: 3100\n",
      "D loss: 7.208\n",
      "G_loss: 5.415\n",
      "\n",
      "Iter: 3200\n",
      "D loss: 7.216\n",
      "G_loss: 6.385\n",
      "\n",
      "Iter: 3300\n",
      "D loss: 7.192\n",
      "G_loss: 5.969\n",
      "\n",
      "Iter: 3400\n",
      "D loss: 7.615\n",
      "G_loss: 7.297\n",
      "\n",
      "Iter: 3500\n",
      "D loss: 7.671\n",
      "G_loss: 5.879\n",
      "\n",
      "Iter: 3600\n",
      "D loss: 6.361\n",
      "G_loss: 6.405\n",
      "\n",
      "Iter: 3700\n",
      "D loss: 6.823\n",
      "G_loss: 5.559\n",
      "\n",
      "Iter: 3800\n",
      "D loss: 7.379\n",
      "G_loss: 5.242\n",
      "\n",
      "Iter: 3900\n",
      "D loss: 6.776\n",
      "G_loss: 6.225\n",
      "\n",
      "Iter: 4000\n",
      "D loss: 7.704\n",
      "G_loss: 5.955\n",
      "\n",
      "Iter: 4100\n",
      "D loss: 7.049\n",
      "G_loss: 7.681\n",
      "\n",
      "Iter: 4200\n",
      "D loss: 7.609\n",
      "G_loss: 5.217\n",
      "\n",
      "Iter: 4300\n",
      "D loss: 8.603\n",
      "G_loss: 7.634\n",
      "\n",
      "Iter: 4400\n",
      "D loss: 7.37\n",
      "G_loss: 5.349\n",
      "\n",
      "Iter: 4500\n",
      "D loss: 7.288\n",
      "G_loss: 7.37\n",
      "\n",
      "Iter: 4600\n",
      "D loss: 7.519\n",
      "G_loss: 5.796\n",
      "\n",
      "Iter: 4700\n",
      "D loss: 6.856\n",
      "G_loss: 5.077\n",
      "\n",
      "Iter: 4800\n",
      "D loss: 7.108\n",
      "G_loss: 7.177\n",
      "\n",
      "Iter: 4900\n",
      "D loss: 6.459\n",
      "G_loss: 4.677\n",
      "\n",
      "Iter: 5000\n",
      "D loss: 6.967\n",
      "G_loss: 4.477\n",
      "\n",
      "Iter: 5100\n",
      "D loss: 7.398\n",
      "G_loss: 5.511\n",
      "\n",
      "Iter: 5200\n",
      "D loss: 8.32\n",
      "G_loss: 5.637\n",
      "\n",
      "Iter: 5300\n",
      "D loss: 8.429\n",
      "G_loss: 5.671\n",
      "\n",
      "Iter: 5400\n",
      "D loss: 8.111\n",
      "G_loss: 6.723\n",
      "\n",
      "Iter: 5500\n",
      "D loss: 6.722\n",
      "G_loss: 6.012\n",
      "\n",
      "Iter: 5600\n",
      "D loss: 6.803\n",
      "G_loss: 6.066\n",
      "\n",
      "Iter: 5700\n",
      "D loss: 7.987\n",
      "G_loss: 6.359\n",
      "\n",
      "Iter: 5800\n",
      "D loss: 8.101\n",
      "G_loss: 4.763\n",
      "\n",
      "Iter: 5900\n",
      "D loss: 7.106\n",
      "G_loss: 4.701\n",
      "\n",
      "Iter: 6000\n",
      "D loss: 7.846\n",
      "G_loss: 4.176\n",
      "\n",
      "Iter: 6100\n",
      "D loss: 8.992\n",
      "G_loss: 4.07\n",
      "\n",
      "Iter: 6200\n",
      "D loss: 9.838\n",
      "G_loss: 7.379\n",
      "\n",
      "Iter: 6300\n",
      "D loss: 8.465\n",
      "G_loss: 5.088\n",
      "\n",
      "Iter: 6400\n",
      "D loss: 7.391\n",
      "G_loss: 4.416\n",
      "\n",
      "Iter: 6500\n",
      "D loss: 9.441\n",
      "G_loss: 5.101\n",
      "\n",
      "Iter: 6600\n",
      "D loss: 6.228\n",
      "G_loss: 4.746\n",
      "\n",
      "Iter: 6700\n",
      "D loss: 7.973\n",
      "G_loss: 5.039\n",
      "\n",
      "Iter: 6800\n",
      "D loss: 9.451\n",
      "G_loss: 7.402\n",
      "\n",
      "Iter: 6900\n",
      "D loss: 8.796\n",
      "G_loss: 3.954\n",
      "\n",
      "Iter: 7000\n",
      "D loss: 8.592\n",
      "G_loss: 5.039\n",
      "\n",
      "Iter: 7100\n",
      "D loss: 7.99\n",
      "G_loss: 5.083\n",
      "\n",
      "Iter: 7200\n",
      "D loss: 8.523\n",
      "G_loss: 4.947\n",
      "\n",
      "Iter: 7300\n",
      "D loss: 11.01\n",
      "G_loss: 6.869\n",
      "\n",
      "Iter: 7400\n",
      "D loss: 7.637\n",
      "G_loss: 5.697\n",
      "\n",
      "Iter: 7500\n",
      "D loss: 8.135\n",
      "G_loss: 5.096\n",
      "\n",
      "Iter: 7600\n",
      "D loss: 8.544\n",
      "G_loss: 5.402\n",
      "\n",
      "Iter: 7700\n",
      "D loss: 7.247\n",
      "G_loss: 5.301\n",
      "\n",
      "Iter: 7800\n",
      "D loss: 11.0\n",
      "G_loss: 5.957\n",
      "\n",
      "Iter: 7900\n",
      "D loss: 9.494\n",
      "G_loss: 4.516\n",
      "\n",
      "Iter: 8000\n",
      "D loss: 8.044\n",
      "G_loss: 3.661\n",
      "\n",
      "Iter: 8100\n",
      "D loss: 7.871\n",
      "G_loss: 5.238\n",
      "\n",
      "Iter: 8200\n",
      "D loss: 6.679\n",
      "G_loss: 5.441\n",
      "\n",
      "Iter: 8300\n",
      "D loss: 7.752\n",
      "G_loss: 5.365\n",
      "\n",
      "Iter: 8400\n",
      "D loss: 7.172\n",
      "G_loss: 4.285\n",
      "\n",
      "Iter: 8500\n",
      "D loss: 9.175\n",
      "G_loss: 4.958\n",
      "\n",
      "Iter: 8600\n",
      "D loss: 8.252\n",
      "G_loss: 4.677\n",
      "\n",
      "Iter: 8700\n",
      "D loss: 7.687\n",
      "G_loss: 5.304\n",
      "\n",
      "Iter: 8800\n",
      "D loss: 7.925\n",
      "G_loss: 6.244\n",
      "\n",
      "Iter: 8900\n",
      "D loss: 7.116\n",
      "G_loss: 4.767\n",
      "\n",
      "Iter: 9000\n",
      "D loss: 9.281\n",
      "G_loss: 5.417\n",
      "\n",
      "Iter: 9100\n",
      "D loss: 7.976\n",
      "G_loss: 5.688\n",
      "\n",
      "Iter: 9200\n",
      "D loss: 9.396\n",
      "G_loss: 6.071\n",
      "\n",
      "Iter: 9300\n",
      "D loss: 8.274\n",
      "G_loss: 4.866\n",
      "\n",
      "Iter: 9400\n",
      "D loss: 7.71\n",
      "G_loss: 5.009\n",
      "\n",
      "Iter: 9500\n",
      "D loss: 8.388\n",
      "G_loss: 4.745\n",
      "\n",
      "Iter: 9600\n",
      "D loss: 7.664\n",
      "G_loss: 5.195\n",
      "\n",
      "Iter: 9700\n",
      "D loss: 8.21\n",
      "G_loss: 5.242\n",
      "\n",
      "Iter: 9800\n",
      "D loss: 8.427\n",
      "G_loss: 4.466\n",
      "\n",
      "Iter: 9900\n",
      "D loss: 6.883\n",
      "G_loss: 4.433\n",
      "\n",
      "Iter: 10000\n",
      "D loss: 6.026\n",
      "G_loss: 3.983\n",
      "\n",
      "Iter: 10100\n",
      "D loss: 7.713\n",
      "G_loss: 5.29\n",
      "\n",
      "Iter: 10200\n",
      "D loss: 8.008\n",
      "G_loss: 5.952\n",
      "\n",
      "Iter: 10300\n",
      "D loss: 7.274\n",
      "G_loss: 4.98\n",
      "\n",
      "Iter: 10400\n",
      "D loss: 8.138\n",
      "G_loss: 4.726\n",
      "\n",
      "Iter: 10500\n",
      "D loss: 8.965\n",
      "G_loss: 5.86\n",
      "\n",
      "Iter: 10600\n",
      "D loss: 7.556\n",
      "G_loss: 4.683\n",
      "\n",
      "Iter: 10700\n",
      "D loss: 8.906\n",
      "G_loss: 5.248\n",
      "\n",
      "Iter: 10800\n",
      "D loss: 7.523\n",
      "G_loss: 5.696\n",
      "\n",
      "Iter: 10900\n",
      "D loss: 7.837\n",
      "G_loss: 5.169\n",
      "\n",
      "Iter: 11000\n",
      "D loss: 7.116\n",
      "G_loss: 5.249\n",
      "\n",
      "Iter: 11100\n",
      "D loss: 6.822\n",
      "G_loss: 5.535\n",
      "\n",
      "Iter: 11200\n",
      "D loss: 9.038\n",
      "G_loss: 5.402\n",
      "\n",
      "Iter: 11300\n",
      "D loss: 6.533\n",
      "G_loss: 6.113\n",
      "\n",
      "Iter: 11400\n",
      "D loss: 6.825\n",
      "G_loss: 4.947\n",
      "\n",
      "Iter: 11500\n",
      "D loss: 7.474\n",
      "G_loss: 4.074\n",
      "\n",
      "Iter: 11600\n",
      "D loss: 7.617\n",
      "G_loss: 5.41\n",
      "\n",
      "Iter: 11700\n",
      "D loss: 8.28\n",
      "G_loss: 6.026\n",
      "\n",
      "Iter: 11800\n",
      "D loss: 7.3\n",
      "G_loss: 5.59\n",
      "\n",
      "Iter: 11900\n",
      "D loss: 6.602\n",
      "G_loss: 5.111\n",
      "\n",
      "Iter: 12000\n",
      "D loss: 8.315\n",
      "G_loss: 5.073\n",
      "\n",
      "Iter: 12100\n",
      "D loss: 8.907\n",
      "G_loss: 4.905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('../out/'):\n",
    "    os.makedirs('../out/')\n",
    "\n",
    "i = 0\n",
    "\n",
    "for it in range(1000000):\n",
    "    if it % 100 == 0:\n",
    "        samples = sess.run(G_sample, feed_dict={Z: sample_z(16, z_size)})\n",
    "\n",
    "        fig = plot(samples)\n",
    "        plt.savefig('../out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "        i += 1\n",
    "        plt.close(fig)\n",
    "\n",
    "    X_mb, _ = mnist.train.next_batch(mb_size)\n",
    "\n",
    "    _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: sample_z(mb_size, z_size)})\n",
    "    _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={Z: sample_z(mb_size, z_size)})\n",
    "\n",
    "\n",
    "    if it % 100 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('D loss: {:.4}'. format(D_loss_curr))\n",
    "        print('G_loss: {:.4}'.format(G_loss_curr))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
